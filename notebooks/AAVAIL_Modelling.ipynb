{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AAVAIL Modelling\n",
    "\n",
    "### Dataset\n",
    "\n",
    "To sum up, AAVAIL managers have asked to build a service that, at any point in time, will predict the revenue for the following month, in general or for specific countries. To keep the development time reasonable the model should be limited to the ten countries with the most revenue.\n",
    "\n",
    "The available data is stored in a set of several json files which represents a monthly data of AAVAIL's transaction for different countries. \n",
    "\n",
    "### Attribute Information:\n",
    "\n",
    "The features found in the data are: \n",
    "\n",
    "- country\n",
    "- customer_id\n",
    "- day\n",
    "- invoice\n",
    "- month\n",
    "- stream_id\n",
    "- times_viewed\n",
    "- total_price\n",
    "- year\n",
    "\n",
    "### Tasks\n",
    "\n",
    "- State the different modeling approaches that you will compare to address the business opportunity.\n",
    "- Iterate on your suite of possible models by modifying data transformations, pipeline architectures, hyperparameters and other relevant factors.\n",
    "- Re-train your model on all of the data using the selected approach and prepare it for deployment.\n",
    "- Articulate your findings in a summary report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import lightgbm as lgb\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from cslib import fetch_ts, engineer_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...fetching data\n",
      "CsLib: Loading Timeseries Data from CSV Files\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(\"..\",\"data\",\"cs-train\")\n",
    "\n",
    "print(\"...fetching data\")\n",
    "\n",
    "ts_data = fetch_ts(data_dir,clean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-06-30'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(ts_data['all'].date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all (607, 7)\n",
      "eire (607, 7)\n",
      "france (607, 7)\n",
      "germany (607, 7)\n",
      "hong_kong (426, 7)\n",
      "netherlands (607, 7)\n",
      "norway (577, 7)\n",
      "portugal (607, 7)\n",
      "singapore (456, 7)\n",
      "spain (607, 7)\n",
      "united_kingdom (607, 7)\n"
     ]
    }
   ],
   "source": [
    "for country, df in ts_data.items():\n",
    "    print(country, df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,dates = engineer_features(ts_data['all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((411, 7), (138, 7), (411,), (138,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Perform a train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=True, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     previous_7  previous_14  previous_28  previous_70  previous_year  \\\n",
      "195   47618.900    87134.610   154257.180   344024.442          0.000   \n",
      "79    28658.491    52755.531   149632.744   336015.705          0.000   \n",
      "479   33452.170    78700.720   146724.940   342694.890     168209.691   \n",
      "109   74230.301   112441.281   175926.804   410792.319          0.000   \n",
      "473   45248.550    83186.210   154930.280   345660.190     198752.871   \n",
      "..          ...          ...          ...          ...            ...   \n",
      "402   57369.120    57369.120   138866.160   793503.392     183479.624   \n",
      "69    28902.811    89895.143   171139.024   400303.044          0.000   \n",
      "261   27755.500    60623.000   129151.260   362049.200          0.000   \n",
      "516   18799.510    51075.470   123990.861   351331.131     142885.530   \n",
      "436   25980.220    53845.610   126857.530   601370.620     141194.594   \n",
      "\n",
      "     recent_invoices  recent_views  \n",
      "195        79.066667   6556.200000  \n",
      "79         72.633333   5775.933333  \n",
      "479        58.600000   6009.266667  \n",
      "109        69.400000   6060.766667  \n",
      "473        52.633333   5526.166667  \n",
      "..               ...           ...  \n",
      "402        46.300000   5048.466667  \n",
      "69         68.633333   5871.500000  \n",
      "261        65.466667   6128.533333  \n",
      "516        55.266667   5213.433333  \n",
      "436        50.600000   5431.200000  \n",
      "\n",
      "[138 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time =  00:00:01\n",
      "mae = 11002\n",
      "mse = 272711018\n",
      "r2_score = 0.958\n",
      "best params = {'rf__criterion': 'mse', 'rf__max_depth': 15, 'rf__n_estimators': 15}\n"
     ]
    }
   ],
   "source": [
    "param_grid_rf = {\n",
    "    'rf__criterion': ['mse','mae'],\n",
    "    'rf__n_estimators': [10,15,20,25],\n",
    "    'rf__max_depth': [5,10,15]\n",
    "    }\n",
    "\n",
    "time_start = time.time()\n",
    "pipe_rf = Pipeline(steps=[('scaler', StandardScaler()), ('rf', RandomForestRegressor())])\n",
    "\n",
    "grid = GridSearchCV(pipe_rf, param_grid=param_grid_rf, cv=5, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "rf_mae =  mean_absolute_error(y_test, y_pred)\n",
    "rf_mse =  mean_squared_error(y_test, y_pred)\n",
    "rf_r2_score = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"train time = \", time.strftime('%H:%M:%S', time.gmtime(time.time()-time_start)))\n",
    "print(\"mae = {:.0f}\".format(rf_mae))\n",
    "print(\"mse = {:.0f}\".format(rf_mse))\n",
    "print(\"r2_score = {:.3f}\".format(rf_r2_score))\n",
    "print(\"best params =\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_gb = {\n",
    "    'gb__criterion': ['mse','mae'],\n",
    "    'gb__n_estimators': [10,15,20,25,50,100]\n",
    "    }\n",
    "\n",
    "time_start = time.time()\n",
    "pipe_gb = Pipeline(steps=[('scaler', StandardScaler()), ('gb', GradientBoostingRegressor())])\n",
    "\n",
    "grid = GridSearchCV(pipe_gb, param_grid=param_grid_gb, cv=5, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "gb_mae =  mean_absolute_error(y_test, y_pred)\n",
    "gb_mse =  mean_squared_error(y_test, y_pred)\n",
    "gb_r2_score = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"train time = \", time.strftime('%H:%M:%S', time.gmtime(time.time()-time_start)))\n",
    "print(\"mae = {:.0f}\".format(gb_mae))\n",
    "print(\"mse = {:.0f}\".format(gb_mse))\n",
    "print(\"r2_score = {:.3f}\".format(gb_r2_score))\n",
    "print(\"best params =\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_dt = {\n",
    "    'lgbm__learning_rate': [0.60,0.75,0.90],\n",
    "    'lgbm__application': ['regression'],\n",
    "    'lgbm__max_depth': [3,4,5]\n",
    "    }\n",
    "\n",
    "time_start = time.time()\n",
    "pipe_ts = Pipeline(steps=[('scaler', StandardScaler()), ('lgbm', LGBMRegressor())])\n",
    "\n",
    "grid = GridSearchCV(pipe_ts, param_grid=param_grid_dt, cv=5, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "dt_mae =  mean_absolute_error(y_test, y_pred)\n",
    "dt_mse =  mean_squared_error(y_test, y_pred)\n",
    "dt_r2_score = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"train time = \", time.strftime('%H:%M:%S', time.gmtime(time.time()-time_start)))\n",
    "print(\"mae = {:.0f}\".format(dt_mae))\n",
    "print(\"mse = {:.0f}\".format(dt_mse))\n",
    "print(\"r2_score = {:.3f}\".format(dt_r2_score))\n",
    "print(\"best params =\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_dt = {\n",
    "    'dt__criterion': ['mse','mae'],\n",
    "    'dt__max_depth': [5,10,20,50],\n",
    "    'dt__min_samples_leaf': [1,2,3,4,5]\n",
    "    }\n",
    "\n",
    "time_start = time.time()\n",
    "pipe_ts = Pipeline(steps=[('scaler', StandardScaler()), ('dt', DecisionTreeRegressor())])\n",
    "\n",
    "grid = GridSearchCV(pipe_ts, param_grid=param_grid_dt, cv=5, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "dt_mae =  mean_absolute_error(y_test, y_pred)\n",
    "dt_mse =  mean_squared_error(y_test, y_pred)\n",
    "dt_r2_score = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"train time = \", time.strftime('%H:%M:%S', time.gmtime(time.time()-time_start)))\n",
    "print(\"mae = {:.0f}\".format(dt_mae))\n",
    "print(\"mse = {:.0f}\".format(dt_mse))\n",
    "print(\"r2_score = {:.3f}\".format(dt_r2_score))\n",
    "print(\"best params =\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
