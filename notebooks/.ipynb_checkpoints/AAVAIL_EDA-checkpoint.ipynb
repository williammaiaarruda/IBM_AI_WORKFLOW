{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AAVAIL Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "To sum up, AAVAIL managers have asked to build a service that, at any point in time, will predict the revenue for the following month, in general or for specific countries. To keep the development time reasonable the model should be limited to the ten countries with the most revenue.\n",
    "\n",
    "The available data is stored in a set of several json files which represents a monthly data of AAVAIL's transaction for different countries. \n",
    "\n",
    "### Attribute Information:\n",
    "\n",
    "The features found in the data are: \n",
    "\n",
    "- country\n",
    "- customer_id\n",
    "- day\n",
    "- invoice\n",
    "- month\n",
    "- stream_id\n",
    "- times_viewed\n",
    "- total_price\n",
    "- year\n",
    "\n",
    "### Testable hypotheses.\n",
    "\n",
    "Some testable hypotheses could be:\n",
    "\n",
    "- Does the new model perform better than the managers' custom methods, i.e. does it achieve a lower Mean Absolute Error (MAE), given the training set and test set provided by the company? \n",
    "\n",
    "- Is the MAE difference significant?\n",
    "\n",
    "- Does customers' behavior vary across countries, i.e. in terms of revenue?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(data_dir):\n",
    "    \"\"\"\n",
    "    laod all json formatted files into a dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    ## input testing\n",
    "    if not os.path.isdir(data_dir):\n",
    "        raise Exception(\"specified data dir does not exist\")\n",
    "        \n",
    "    if not len(os.listdir(data_dir)) > 0:\n",
    "        raise Exception(\"specified data dir does not contain any files\")\n",
    "\n",
    "    file_list = [os.path.join(data_dir,f) for f in os.listdir(data_dir) if re.search(\"\\.json\",f)]\n",
    "    \n",
    "    correct_columns = ['country', 'customer_id', 'day', 'invoice', 'month', 'price', 'stream_id', 'times_viewed', 'year']\n",
    "\n",
    "    ## read data into a temp structure\n",
    "    all_months = {}\n",
    "    for file_name in file_list:\n",
    "        df = pd.read_json(file_name)\n",
    "        all_months[os.path.split(file_name)[-1]] = df\n",
    "\n",
    "    ## ensure the data are formatted with correct columns\n",
    "    for f,df in all_months.items():\n",
    "        cols = set(df.columns.tolist())\n",
    "        if 'StreamID' in cols:\n",
    "             df.rename(columns={'StreamID':'stream_id'},inplace=True)\n",
    "        if 'TimesViewed' in cols:\n",
    "            df.rename(columns={'TimesViewed':'times_viewed'},inplace=True)\n",
    "        if 'total_price' in cols:\n",
    "            df.rename(columns={'total_price':'price'},inplace=True)\n",
    "\n",
    "        cols = df.columns.tolist()\n",
    "        if sorted(cols) != correct_columns:\n",
    "            raise Exception(\"columns name could not be matched to correct cols\")\n",
    "\n",
    "    ## concat all of the data\n",
    "    df = pd.concat(list(all_months.values()),sort=True)\n",
    "    \n",
    "    years,months,days = df['year'].values,df['month'].values,df['day'].values \n",
    "    \n",
    "    dates = [\"{}-{}-{}\".format(years[i],str(months[i]).zfill(2),str(days[i]).zfill(2)) for i in range(df.shape[0])]\n",
    "    \n",
    "    df['invoice_date'] = np.array(dates,dtype='datetime64[D]')\n",
    "    \n",
    "    df['invoice'] = [re.sub(\"\\D+\",\"\",i) for i in df['invoice'].values]\n",
    "    \n",
    "    ## sort by date and reset the index\n",
    "    df.sort_values(by='invoice_date',inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.DataFrame()\n",
    "\n",
    "data_dir = os.path.join(\"..\",\"data\",\"cs-train\")\n",
    "\n",
    "df_total = fetch_data(data_dir)\n",
    "\n",
    "print(df_total.shape)\n",
    "\n",
    "df_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of different days covered by the dataset\")\n",
    "len(set(df_total['invoice_date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking Infomation about Dataset Columns including its datatypes and missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.info(all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df_total)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_zero_values_table(df):\n",
    "\n",
    "    zero_val = (df == 0.00).astype(int).sum(axis=0)\n",
    "    \n",
    "    mis_val = df.isnull().sum()\n",
    "    \n",
    "    mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "    \n",
    "    mz_table = pd.concat([zero_val, mis_val, mis_val_percent], axis=1)\n",
    "    mz_table = mz_table.rename(columns = {0 : 'Zero Values', 1 : 'Missing Values', 2 : '% of Total Values'})\n",
    "    mz_table['Total Zero Missing Values'] = mz_table['Zero Values'] + mz_table['Missing Values']\n",
    "    mz_table['% Total Zero Missing Values'] = 100 * mz_table['Total Zero Missing Values'] / len(df)\n",
    "    mz_table['Data Type'] = df.dtypes\n",
    "    mz_table = mz_table[mz_table.iloc[:,1] != 0].sort_values('% of Total Values', ascending=False).round(1)\n",
    "    \n",
    "    print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns and \" + str(df.shape[0]) + \" Rows.\\n\" \n",
    "    \"There are \" + str(mz_table.shape[0]) +\n",
    "    \" columns that have missing values.\")\n",
    "    \n",
    "    return mz_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_zero_values_table(df_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Alphanumeric Characters from Invoice Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeAlphanumeric(InputString):\n",
    "    return re.sub(r'[^0-9]', '', InputString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total['invoice'] = df_total['invoice'].apply(removeAlphanumeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Lines where Price < 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# See if price is negative. If yes, remove\n",
    "df_total[df_total['price'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = df_total[df_total['price'] >= 0]\n",
    "df_total.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countries with Higher Revenues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Countries With Most Entries\")\n",
    "df_total['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev = df_total[['country', 'price']].groupby('country').sum().sort_values('price', ascending=False)\n",
    "df_rev = df_rev.rename(columns={'price': 'revenue'})\n",
    "\n",
    "df_rev_by_country = df_rev.reset_index()\n",
    "\n",
    "print(\"Top 10 Countries in terms of Revenue\")\n",
    "print(df_rev.shape)\n",
    "\n",
    "df_rev[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are quite few records for several countries with least revenues. So it would be better to get a subset of top 10 countries with highest revenue.  Perform further investigation based on this subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subset of only top 10 countries for plots\n",
    "list_top_10 = ['United Kingdom', 'EIRE', 'Germany', 'France',\n",
    "               'Norway', 'Spain', 'Hong Kong', 'Portugal',\n",
    "               'Singapore', 'Netherlands']\n",
    "df_top = df_total[df_total['country'].isin(list_top_10)]\n",
    "df_top.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,6))\n",
    "ax2 = fig.add_subplot(121)\n",
    "plt.title('Distribution of Price by Top 10 Countries')\n",
    "table2 = pd.pivot_table(df_top, index = ['country'], values = 'price')\n",
    "table2.plot(kind='barh',ax=ax2, colormap=\"coolwarm\")\n",
    "ax2.set_xlabel(\"Price\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,6))\n",
    "ax2 = fig.add_subplot(121)\n",
    "\n",
    "plt.title('Distribution of Times Viewed by Top 10 Countries')\n",
    "table2 = pd.pivot_table(df_top, index = ['country'], values = 'times_viewed')\n",
    "table2.plot(kind='barh',ax=ax2, colormap=\"coolwarm\")\n",
    "ax2.set_xlabel(\"Number of times viewed\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,6))\n",
    "ax1 = fig.add_subplot(121)\n",
    "\n",
    "plt.title('Distribution of Price by Year on Top 10 Countries')\n",
    "table1 = pd.pivot_table(df_top,index='country',columns='year',values=\"price\")\n",
    "table1.plot(kind='bar',ax=ax1, colormap=\"GnBu\")\n",
    "ax1.set_ylabel(\"Price\")\n",
    "ax1.set_ylim((0,120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,6))\n",
    "ax2 = fig.add_subplot(121)\n",
    "\n",
    "plt.title('Distribution of Times Viewed by Year on Top 10 Countries')\n",
    "table2 = pd.pivot_table(df_top,index='country',columns='year',values=\"times_viewed\")\n",
    "table2.plot(kind='bar',ax=ax2, colormap=\"GnBu\")\n",
    "ax2.set_ylabel(\"Number of Views\")\n",
    "ax2.set_ylim((0,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10,5))\n",
    "\n",
    "#Original Data (High Dispersion)\n",
    "axes[0].set_title('Distribution of Price')\n",
    "sns.distplot(df_top.price, ax=axes[0], kde=False)\n",
    "axes[0].grid()\n",
    "\n",
    "axes[1].set_title('Distribution of log(Price + 1)')\n",
    "sns.distplot(np.log1p(df_top.price), ax=axes[1], fit=norm, kde=False)\n",
    "axes[1].set_xticks(range(0,6))\n",
    "axes[1].grid()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo Feature com transformação logaritimica\n",
    "df_top['log_price'] = np.log1p(df_top.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (10, 5)})\n",
    "plt.title('Distribution of Times Viewed')\n",
    "sns.distplot(df_total.times_viewed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(x='invoice_date', y='price', data=df_top.groupby(pd.Grouper(key='invoice_date', freq='B')).sum().reset_index(), kind='line')\n",
    "g.fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to carry out a time series analysis, record of each day should be considered and the dataframe should be in a chronological order so that forecasting models can fit and provide revenue i.e price for the following month. Let's start by aggregating the transactions by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_top.groupby(['invoice_date']).agg({'times_viewed':'sum', 'price':'sum',\n",
    "                                        'country':'first',}).reset_index()\n",
    "df_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_agg.head(5))\n",
    "print(df_agg.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
